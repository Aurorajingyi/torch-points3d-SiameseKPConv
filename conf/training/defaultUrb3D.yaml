# Those arguments defines the training hyper-parameters
training:
    epochs: 100 # 原本为550
    num_workers: 1 # 原本是10
    batch_size: 2 # 原本是10
    shuffle: True
    resume: False #新加
    cuda: 0 # -1 -> no cuda otherwise takes the specified index
    precompute_multi_scale: False # Compute multiscate features on cpu for faster training / inference
    optim:
        base_lr: 0.01
        grad_clip: 100
        optimizer:
            class: SGD #Adam
            params:
                momentum: 0.98
                lr: ${training.optim.base_lr} # The path is cut from training
                weight_decay: 1e-3
        lr_scheduler: ${lr_scheduler}
        bn_scheduler:
            bn_policy: "step_decay"
            params:
                bn_momentum: 0.02
                bn_decay: 0.9
                decay_step : 1000
                bn_clip : 1e-2
        early_stop: 50 # Set to -1 if no early stopping wanted else indicate the number of step with augmentation of miou_ch on val ds
    weight_name: "latest" # Used during resume, select with model to load from [miou, macc, acc..., latest]
    enable_cudnn: True
    checkpoint_dir: "" # 修改如下
    #checkpoint_dir: outputs/${now:%Y-%m-%d}/checkpoints
    #save_ckpt_freq: 5 # 每 5 个 epoch 自动保存一次 checkpoint


# Those arguments within experiment defines which model, dataset and task to be created for benchmarking
# parameters for Weights and Biases
wandb:
    entity: ""
    project: "Change_detection"
    log: False
    notes: "Urb3DCD "
    name: "Urb3DCD SiameseKPConv"
    public: True # It will be display the model within wandb log, else not.
    config:
        model_name: ${model_name}


# parameters for TensorBoard Visualization
tensorboard:
    log: False
